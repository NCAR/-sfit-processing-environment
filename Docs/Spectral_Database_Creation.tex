\documentclass[12pt, letterpaper]{article}

% font
\usepackage[T1]{fontenc}
\usepackage{hyperref}

% math
\usepackage{mathcomp}

% document formatting
\usepackage{geometry}
\geometry{letterpaper, left=1in, right=1in, top=1in, bottom=1in}
\usepackage{changepage}

% lists
\usepackage{enumitem}

% tables
\usepackage{tabularx}
\newcolumntype{S}{@{\stepcounter{Definition}\theDefinition.~} >{}l @{~ : ~}X@{}}
\newcounter{Definition}[subsection]

\usepackage{textcomp}

% graphics
\usepackage{graphicx}
\usepackage{float}
\graphicspath{ {./} }

% colors
\usepackage{color}
\definecolor{light-gray}{gray}{0.85}

% my own macros!
\usepackage{xspace}
\newcommand{\code}[1]{\colorbox{light-gray}{\texttt{#1}}}
\newcommand{\apr}{\`{a} priori\xspace}

% header / footer
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
\fancyhead[LE,RO]{\slshape \leftmark}
\fancyhead[LO,RE]{\slshape \rightmark}
\fancyfoot[LE,RO]{\thepage}

% author tags
\usepackage{authblk}
\renewcommand\Affilfont{\itshape\small}
\renewcommand\Authands{ and }

% multiple columns
\usepackage{multicol}

% code listing
\usepackage{listings}
\lstset{language=FORTRAN} 

\title{FTS Profile Retrieval Pre and Post Processing}

\author[1]{Eric Nussbaumer \thanks{corresponding author: ebaumer@ucar.edu +1 (303) 497-1861}}
\affil[1]{National Center for Atmospheric Research, Boulder, CO, USA}

\date{September 2015}

\begin{document}

\begin{titlepage}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

\begin{abstract}
  \begin{adjustwidth}{2em}{2em} 
    \large{
      \emph{
This document outlines the creation of the spectral database as well as the profiles for pressure, temperature, and water vapor.
}}
      
  \end{adjustwidth}

\end{abstract}

\end{titlepage}
 
\newpage
%------------------
% Table of contents
%------------------
\tableofcontents
\newpage


\section{Introduction} 
\label{sec:intro}



\section{Pre-Processing}
The spectral database and ZPTW (altitude, pressure, temperature, and water vapor) profiles are necessary pre-processing steps to retrievals. The spectral database holds information pertaining to each of the measurements. A spectral database is unique to each site\\

\noindent The majority of information in the spectral database comes from the OPUS file itself; however, we append meteorological data from local weather weather stations.\\

\noindent There are several steps in creating the spectral database:\\

\begin{enumerate}
\item Creating the initial spectral database
\item Re-formatting the house log data files
\item Re-formatting the external station weather data
\item Appending the initial spectral database with house an external station weather data
\end{enumerate}

\noindent Note that not all sites have house or external station weather data.\\

\begin{tabular}{ l l l }
\textbf{Station} & \textbf{House Data} & \textbf{External Station Data} \\
\hline
MLO   & Yes & Yes (CMDL) \\
TAB   & Yes & No         \\
FL0   & No  & Yes (EOL)  \\
\end{tabular} \\

\noindent The necessary python files are located in the \href{https://git.ucar.edu/?p=sfit-processing-environment.git}{sfit-processing-environment} git repository. \\

\subsection{Pulling Data}
\label{sec:PD}
Both the ancillary data as well as the OPUS files need to be downloaded from various sources. The OPUS data is automatically downloaded from MLO and TAB by the program pullRemoteData2.py. This program is set on a cron tab to download data everyday.

\noindent The following table shows where the OPUS data is downloaded to.\\

\begin{tabular}{ l l }
\textbf{Data} & \textbf{Local Storage} \\
\hline
MLO   & otserver:/ya4/id/mlo/   \\
TAB   & otserver:/ya4/id/tab/   \\
\end{tabular} \\

\noindent The supporting data is pulled with a program using wget. The program is pullAncillaryData.py and is located at: /data/bin/. This program has been setup in cron tab to pull data everyday. The program pullAncillaryData.py gets the following data: NCEP nmc, NCEP I re-analysis, EOL, and CMDL. \\

\noindent ERA-Interim data must be manually pulled through the server data-access.ucar.edu.\\

\noindent The following table shows the local storage of the ancillary data\\

\begin{tabular}{ l l }
\textbf{Data} & \textbf{Local Storage} \\
\hline
WACCM               & otserver:/data/Campaign/TAB,MLO,FL0/waccm/             \\
NCEP nmc Height     & otserver:/data1/ancillary\_data/NCEP\_NMC/height/      \\
NCEP nmc Temp       & otserver:/data1/ancillary\_data/NCEP\_NMC/temp/        \\
NCEP I Height       & otserver:/data1/ancillary\_data/NCEPdata/NCEP\_hgt/    \\
NCEP I Shum         & otserver:/data1/ancillary\_data/NCEPdata/NCEP\_Shum/   \\
NCEP I Temp         & otserver:/data1/ancillary\_data/NCEPdata/NCEP\_Temp/   \\
NCEP I Trpp         & otserver:/data1/ancillary\_data/NCEPdata/NCEP\_trpp/   \\
ERA-Interim         & otserver:/data1/ancillary\_data/ERAdata/               \\
EOL                 & otserver:/data1/ancillary\_data/fl0/eol/               \\
CMDL Hourly         & otserver:/data1/ancillary\_data/mlo/cmdl/Hourly\_Data/ \\
CMDL Minute         & otserver:/data1/ancillary\_data/mlo/cmdl/Minute\_Data/ \\
\end{tabular} \\

\subsection{Initial Quality Check}
An initial quality check on the spectrum is done using the IDL program ckop.pro. This program allows the user to look through each individual spectra and discard or keep it. Once this is completed the data should be copied over from /ya4/id/(mlo,tab,fl0) to the directory /data1/(mlo,tab,fl0).\\

\begin{tabular}{ l l }
\textbf{Program} & \textbf{Description} \\
\hline
ckop.pro         & IDL program to check OPUS spectra \\
\end{tabular} \\

\section{Spectral Database}
\subsection{Initial Spectral Database}
\label{sec:ISD}
The initial spectral database file is created by running ckopus on the various raw OPUS file. A python program is created to manage the creation of the initial spectral database file (mkSpecDB.py). The program will create a new spectral database file or append an already existing file. Associated with mkSpecDB.py is an input file. The input file allows one to specify the starting and ending date to process, the station, and the various directories and files to use. In addition, one can specify additional ckopus flags to use in the ckopus call. There are logical flags which control the creating of a file which list the folders processed and whether bnr files are created. These files are located under the SpectralDatabase folder of the git repository.\\

\begin{tabular}{ l l }
\textbf{Program} & \textbf{Description} \\
\hline
mkSpecDB.py         & Main program to create initial spectral database \\
specDBInputFile.py  & Input file for mkSpecDB.py program               \\
\end{tabular} \\


\subsection{House Data}
\label{sec:HD}

House data is data that is recorded by the FTS autonomous system, such as outside temperature, pressure, wind direction, etc. The format of this data has changed for each station over time as the instrument gets modified or upgraded. A python program (station\_house\_reader.py) is created to read the various formats and create a standardized file. There is one file for each year. There are no input files for the station\_house\_reader.py program. The time range, station identifier, and directories are specified directly in the program under the main function. An excel spreadsheet describes the various formats for the house log files for MLO and TAB.\\

\begin{tabular}{ l l }
\textbf{Program} & \textbf{Description} \\
\hline
station\_house\_reader.py & Main program to read house data files\\
HouseReaderC.py           & Supporting program with formats of previous house data files \\
HouseDataLog.xlsx         & Excel file with format of house log files\\
\end{tabular} \\

These programs are located in the ExternalData folder of the git repository.


\subsection{External Station Data}
\label{sec:ED}

There are currently two external station data sources used (EOL for FL0, and CMDL for MLO) only the EOL data needs to be pre-processed. The original format of this data is in netcdf files. The program read\_FL0\_EOL\_data.py reads the daily netcdf files and creates a yearly text file. There are no input files for read\_FL0\_EOL\_data.py program. The year of interest and directories of data are specified directly in the program under the main function.  The program pullAncillaryData.py pulls the CMDL and EOL data from each individual ftp site. \\

\begin{tabular}{ l l }
\textbf{Program} & \textbf{Description} \\
\hline
pullAncillaryData.py    & Program to automatically pull EOL and CMDL data\\
read\_FL0\_EOL\_data.py & Main program to read EOL and CMDL data \\
\end{tabular} \\

\noindent These programs are located in the ExternalData folder of the git repository.

\subsection{Append Spectral Database File}
\label{sec:ASDF}
The final step is appending the initial spectral database file with the house and external station weather data. A python program was created to accomplish this (appendSpecDB.py). The program appendSpecDB.py reads in the initial spectral database file. It then searches the house and external station files for weather data at the time of observation, plus a certain number of minutes specified by the user. The mean of the data collected is calculated and a new spectral database file is created. If no data is present missing values are used. Associated with appendSpecDB.py is an input file. The input file allows one to specify directories and files, year to process, station, how many minutes to use for averaging, and whether to create a comma separated or pre-specified formatted new spectral database file.\\

\begin{tabular}{ l l }
\textbf{Program} & \textbf{Description} \\
\hline
appendSpecDB.py         & Program to create the append spectral database file\\
appndSpecDBInputFile.py & Input file for appendSpecDB.py \\
\end{tabular} \\

\noindent \textit{Note:A warning message will often appear when running this program originating from the python numpy module. This warning is a result of numpy taking the mean of an empty array. This is handled by the main program.}

\section{ZPTW Profiles}
The pressure, temperature, and water vapor profiles can be created from several outside sources. Temperature and pressure profiles are taken from NCEP nmc data; while currently only water profiles are taken from NCEP I and ERA-Interim re-analysis data. Both NCEP and ERA-Interim data are interpolated with WACCM data to reach 120km vertical height. The profiles are daily averages and they reside in the data directories (/data1/tab,mlo,fl0/).\\

\noindent The following is a table showing the various reference profiles, their sources, along with the associated file names.\\

\begin{tabular}{ l l l }
\textbf{Profile Type} & \textbf{Source} & \textbf{File Name} \\
\hline
Temperature   & NCEP nmc          & ZPT.nmc.120 \\
Pressure      & NCEP nmc          & ZPT.nmc.120 \\
Water Vapor   & WACCM             & w-120.v1    \\
Water Vapor   & NCEP I            & w-120.v3    \\
Water Vapor   & ERA-Interim       & w-120.v4    \\
Water Vapor   & Retrieved         & w-120.YYYYMMDD.HHMMSS.v99    \\
Water Vapor   & Retrieved Daily   & w-120.v5    \\
\end{tabular} \\


\noindent The following table shows the various sources for the data.\\

\begin{tabular}{ l l }
\textbf{Data} & \textbf{Source} \\
\hline
WACCM              & Local (otserver:/data/Campaign/TAB,MLO,FL0/waccm/  \\
NCEP nmc           & ftp://ftp.cpc.ncep.noaa.gov/ndacc/ncep/\\
NCEP I re-analysis & ftp://ftp.cdc.noaa.gov/Datasets/ncep.reanalysis.dailyavgs/          \\
ERA-Interim re-analysis   & /glade/p/rda/data/ds627.0/ei.oper.an.pl/         \\
\end{tabular} \\


\subsection{Pressure \& Temperature Profiles}
\label{sec:PT}
Pressure and temperature profiles in the ZPT.nmc.120 files come from NCEP nmc data. The NCEP nmc data is vertically interpolated with WACCM data to reach 120km. In the event that the NCEP nmc data is not available for a particular day, the WACCM data is substituted.\\

\noindent The NCEP nmc data must first be formatted. This is done using the program NCEPnmcFormat.py.\\

\noindent After formating the NCEP nmc data one can create the altitude, pressure, and temperature profiles using the program MergPrf.py. This program also creates water profiles from WACCM data (v1).\\

\begin{tabular}{ l l }
\textbf{Program} & \textbf{Description} \\
\hline
NCEPnmcFormat.py & Program to format the NCEP nmc data\\
MergPrf.py       & Main program to create ZPT and water files from NCEP data\\
\end{tabular} \\

\subsection{NCEP I \& ERA Interim Water Profiles}
\label{sec:ERAInt}
The ERA-Interim daily profiles are calculated from 6 hourly data. Both the 6 hourly and daily data for profiles are created. The ERA-Interim data is housed locally at NCAR in the CISL Research Data Archive. There is a three month lag between the current date and when the data becomes available. The data is hosted on /glade/ and can be accessed through the data-access.ucar.edu server. The data can be found at: /glade/p/rda/data/ds627.0/ei.oper.an.pl/. The following steps should be used to pre-process the data:\\

\begin{enumerate}
\item Copy over the data from glade
\item Convert GRIB format files to NetCDF files using cnvrtNC.py
\item Create water profiles using ERAwaterPrf.py
\end{enumerate}

\noindent The NCEP I re-analysis data are already daily averages. The grid resolution of NCEP I is less than ERA-interim. In addition ERA-Interim assimilates GPS occultation data. It is preferable to use ERA-Interim over NCEP I. The program to create water profiles from NCEP I data is NCEPwaterPrf.py.\\

\begin{tabular}{ l l }
\textbf{Program} & \textbf{Description} \\
\hline
cnvrtNC.py     & Program to convert ERA-Interim GRIB files to NetCDF files\\
ERAwaterPrf.py & Program to extract daily averaged water profiles from ERA-Interim\\
NCEPwaterPrf.py& Program to create daily water profiles from NCEP I\\
\end{tabular} \\


\subsection{Retrieved Water Profiles}
\label{sec:RWP}
For all sites (MLO,TAB, and FL0) water is retrieved when available. This water can be used as a prior for other retrievals. The program retWaterPrf.py creates w-120.YYYYMMDD.HHMMSS.v99 for each retrieval. These files are stored in the data directories (/data1/tab,mlo,fl0/). A daily average of these profiles can be created using the program retWaterPrfDaily.py. These daily averages are also stored in the main data directories (/data1/tab,mlo,fl0/).\\

\begin{tabular}{ l l }
\textbf{Program} & \textbf{Description} \\
\hline
retWaterPrf.py      & Program to create water profiles from water retrieval\\
retWaterPrfDaily.py & Program to create daily average profiles from water retrievals\\
\end{tabular} \\


\subsection{Steps for Pre-Processing}
\label{sec:SCSD}

\begin{itemize}
\item Download OPUS and ancillary data (This is done automatically)
\item Check OPUS spectra
\item Copy spectra from /ya4/id/(mlo,tab,fl0) to /data1/(mlo,tab,fl0)
\item Create initial database
\item Format house data
\item Format external station data
\item Create appended spectral database
\item Create Altitude, Pressure, and Temperature profiles (ZPT.nmc.120)
\item Create water profiles (v1,v2,v3,v4,v5,v99)
\end{itemize}


\section{Processing}
\subsection{Layer0}

\subsection{Layer1}


\section{Post-Processing}



\end{document}




